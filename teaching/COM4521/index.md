---
title: Dr Paul Richmond - COM4521 & COM 6521 Introduction to Parallel Computing with GPUs
layout: homepage
---

# About the Course

Accelerator architectures are discrete processing units which supplement a base processor with the objective of providing advanced performance at lower energy cost. Performance is gained by a design which favours a high number of parallel compute cores at the expense of imposing significant software challenges. This module looks at accelerated computing from multi-core CPUs to GPU accelerators with many TFlops of theoretical performance. The module will give insight into how to write high performance code with specific emphasis on GPU programming with NVIDIA CUDA GPUs. A key aspect of the module will be understanding what the implications of program code are on the underlying hardware so that it can be optimised.

# Aims of the Course

* To introduce modern accelerator architectures, explain the difference between data and task parallelism and raise awareness into how the practical and theoretical performance of architectures differs.
* To give practical knowledge of how GPU programs operate and how they can be utilised for high performance applications.
* To develop an understanding of the importance of benchmarking and profiling in order to recognise factors limiting performance and to address these through optimisation.

# Objectives

By the end of this course students will be able to;

* Understand how to write C programs and manage memory allocation manually.
* Utilise OpenMP to write programs for multi core architectures to improve code performance.
* Be able to describe and discuss performance techniques for multi core processors.
* Program GPUs for general purpose use with the CUDA language.
* Appreciate how GPU program performance can be improved through intelligent caching.
* Appreciate the scope, potential and limitations of accelerators for improving code performance.
* Benchmark and profile GPU programs.
* Identify limiting factors to code performance and address these through architecture specific optimisation techniques.
* Recognise and understand the importance of parallel primitives (such as scan and reduce) and understand how these can be implemented with data parallelism.
* Understand how to display GPU data graphically by integrating CUDA programs with OpenGL.

# Recommended Reading

I'm not advocating that you download these for free but if you search for them on google there may or may not be pdf versions available...

* Edward Kandrot, Jason Sanders, "CUDA by Example: An Introduction to General-Purpose GPU Programming", Addison Wesley 2010.
* Brian Kernighan, Dennis Ritchie, “The C Programming Language (2nd Edition)”, Prentice Hall 1988.

# Lecture Notes

Not available yet

# Labs

Also not available yet

# Discussion and Annoucements

Discussion and annoucements will be made via the modules Gooogle Group.

[https://groups.google.com/a/sheffield.ac.uk/d/forum/com4521-group](https://groups.google.com/a/sheffield.ac.uk/d/forum/com4521-group)

# Calendar

You can add this calendar to your University of Sheffield Google Calendar by searching for COM4521 and COM6521

<iframe src="https://calendar.google.com/calendar/embed?src=sheffield.ac.uk_4gq0ug3uf8dlts9d21gp4l1des%40group.calendar.google.com&ctz=Europe/London" style="border: 0" width="800" height="600" frameborder="0" scrolling="no"></iframe>
